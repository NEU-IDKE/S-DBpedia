{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8814a6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_path = ['./data/DBpedia_combin/DBpedia_duplicates_filterOntology_dropMaxRelationship_filterGeo.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c680c2e6",
   "metadata": {},
   "source": [
    "## 删除出现次数少的50%实体和关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ecbc5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for p in data_path:\n",
    "p = data_path[0]\n",
    "df = pd.read_csv(p, sep='\\t', names=['head', 'relationship', 'tail'])\n",
    "ent = pd.concat([df['head'], df['tail']])\n",
    "df_ent_count = pd.DataFrame(ent.value_counts())\n",
    "df_ent_count = df_ent_count.reset_index()\n",
    "df_ent_half = df_ent_count.iloc[:df_ent_count.shape[0]//2]\n",
    "df_ent_half[0] = 1\n",
    "df_ent_half.columns = ['head', 0]\n",
    "df_ent_half_1 = df_ent_half.copy()\n",
    "df_ent_half_1.columns = ['tail', 2]\n",
    "df_rela_count = pd.DataFrame(df['relationship'].value_counts())\n",
    "df_rela_count = df_rela_count.reset_index()\n",
    "df_rela_half = df_rela_count.iloc[:df_rela_count.shape[0]//2]\n",
    "df_rela_half['relationship'] = 1\n",
    "df_rela_half.columns = ['relationship', 1]\n",
    "df = pd.merge(df, df_ent_half, on='head', how='left')\n",
    "df = pd.merge(df, df_ent_half_1, on='tail', how='left')\n",
    "df = pd.merge(df, df_rela_half, on='relationship', how='left')\n",
    "df = df[df[0] >= 1]\n",
    "df = df[df[1] >= 1]\n",
    "df = df[df[2] >= 1]\n",
    "df = df[['head', 'relationship', 'tail']]\n",
    "entity_num = len(pd.concat([df['head'], df['tail']]).unique())\n",
    "rela_num = len(df['relationship'].unique())\n",
    "triplets_num = df.shape[0]\n",
    "print(p, triplets_num, entity_num, rela_num)\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv(p[:-4] + '_dropLessHalfEntAndRela.csv', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab30f57",
   "metadata": {},
   "source": [
    "## 删除出现次数多的5%实体和关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bca541ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maocy/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == \"__main__\":\n",
      "/home/maocy/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/DBpedia_combin/DBpedia_duplicates_filterOntology_dropMaxRelationship_filterGeo.csv 33236 48542 260\n"
     ]
    }
   ],
   "source": [
    "# for p in data_path:\n",
    "drop_rate = 0.05\n",
    "p = data_path[0]\n",
    "df = pd.read_csv(p, sep='\\t', names=['head', 'relationship', 'tail'])\n",
    "ent = pd.concat([df['head'], df['tail']])\n",
    "df_ent_count = pd.DataFrame(ent.value_counts())\n",
    "df_ent_count = df_ent_count.reset_index()\n",
    "df_ent_half = df_ent_count.iloc[round(df_ent_count.shape[0] * drop_rate):]\n",
    "df_ent_half[0] = 1\n",
    "df_ent_half.columns = ['head', 0]\n",
    "df_ent_half_1 = df_ent_half.copy()\n",
    "df_ent_half_1.columns = ['tail', 2]\n",
    "df_rela_count = pd.DataFrame(df['relationship'].value_counts())\n",
    "df_rela_count = df_rela_count.reset_index()\n",
    "df_rela_half = df_rela_count.iloc[round(df_rela_count.shape[0] * drop_rate):]\n",
    "df_rela_half['relationship'] = 1\n",
    "df_rela_half.columns = ['relationship', 1]\n",
    "df = pd.merge(df, df_ent_half, on='head', how='left')\n",
    "df = pd.merge(df, df_ent_half_1, on='tail', how='left')\n",
    "df = pd.merge(df, df_rela_half, on='relationship', how='left')\n",
    "df = df[df[0] >= 1]\n",
    "df = df[df[1] >= 1]\n",
    "df = df[df[2] >= 1]\n",
    "df = df[['head', 'relationship', 'tail']]\n",
    "entity_num = len(pd.concat([df['head'], df['tail']]).unique())\n",
    "rela_num = len(df['relationship'].unique())\n",
    "triplets_num = df.shape[0]\n",
    "print(p, triplets_num, entity_num, rela_num)\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_csv(p[:-4] + '_dropMost5PersentEntAndRela.csv', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9fd750",
   "metadata": {},
   "source": [
    "## 提取前r%的实体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22de4b38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maocy/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/DBpedia_combin/DBpedia_duplicates_filterOntology_dropMaxRelationship_filterGeo.csv 161029 45240 173\n",
      "./data/DBpedia_combin/DBpedia_duplicates_filterOntology_dropMaxRelationship_filterGeo.csv 334481 91897 236\n",
      "./data/DBpedia_combin/DBpedia_duplicates_filterOntology_dropMaxRelationship_filterGeo.csv 677676 185286 264\n",
      "./data/DBpedia_combin/DBpedia_duplicates_filterOntology_dropMaxRelationship_filterGeo.csv 1527049 465046 286\n"
     ]
    }
   ],
   "source": [
    "# for p in data_path:\n",
    "get_rates = [0.05, 0.1, 0.2, 0.5]\n",
    "for drop_rate in get_rates:\n",
    "    p = data_path[0]\n",
    "    df = pd.read_csv(p, sep='\\t', names=['head', 'relationship', 'tail'])\n",
    "    ent = pd.concat([df['head'], df['tail']])\n",
    "    df_ent_count = pd.DataFrame(ent.value_counts())\n",
    "    df_ent_count = df_ent_count.reset_index()\n",
    "    df_ent_half = df_ent_count.iloc[:round(df_ent_count.shape[0] * drop_rate)]\n",
    "    df_ent_half[0] = 1\n",
    "    df_ent_half.columns = ['head', 0]\n",
    "    df_ent_half_1 = df_ent_half.copy()\n",
    "    df_ent_half_1.columns = ['tail', 2]\n",
    "    # df_rela_count = pd.DataFrame(df['relationship'].value_counts())\n",
    "    # df_rela_count = df_rela_count.reset_index()\n",
    "    # df_rela_half = df_rela_count.iloc[round(df_rela_count.shape[0] * drop_rate):]\n",
    "    # df_rela_half['relationship'] = 1\n",
    "    # df_rela_half.columns = ['relationship', 1]\n",
    "    df = pd.merge(df, df_ent_half, on='head', how='left')\n",
    "    df = pd.merge(df, df_ent_half_1, on='tail', how='left')\n",
    "    # df = pd.merge(df, df_rela_half, on='relationship', how='left')\n",
    "    df = df[df[0] >= 1]\n",
    "    # df = df[df[1] >= 1]\n",
    "    df = df[df[2] >= 1]\n",
    "    df = df[['head', 'relationship', 'tail']]\n",
    "    entity_num = len(pd.concat([df['head'], df['tail']]).unique())\n",
    "    rela_num = len(df['relationship'].unique())\n",
    "    triplets_num = df.shape[0]\n",
    "    print(p, triplets_num, entity_num, rela_num)\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(p[:-4] + f'_get{round(drop_rate * 100)}Ent.csv', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc0df771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5151515151515151"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / 0.66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c7ff15d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/DBpedia-snapshot-2022-03/DBpedia-snapshot-2022-03_duplicates_filterOntology_dropMaxRelationship_filterGeo.csv 119109 33754 134\n",
      "./data/DBpedia_online/DBpedia_duplicates_filterOntology_dropMaxRelationship_filterGeo.csv 2527 1554 55\n"
     ]
    }
   ],
   "source": [
    "for p in data_path:\n",
    "    df = pd.read_csv(p, sep='\\t', names=['head', 'relationship', 'tail'])\n",
    "    ent = pd.concat([df['head'], df['tail']]).unique()\n",
    "    relationship = df['relationship'].unique()\n",
    "    ent_counter = {i: 0 for i in ent}\n",
    "    rela_counter = {i:0 for i in relationship}\n",
    "    for i in range(df.shape[0]):\n",
    "        head = df['head'][i]\n",
    "        tail = df['tail'][i]\n",
    "        rela = df['relationship'][i]\n",
    "        ent_counter[head] += 1\n",
    "        rela_counter[rela] += 1\n",
    "        ent_counter[tail] += 1\n",
    "    df_entity_counter = pd.DataFrame(ent_counter.items())\n",
    "    df_rela_counter = pd.DataFrame(rela_counter.items())\n",
    "    df_entity_counter.columns = ['head', 'num_h']\n",
    "    df = pd.merge(df, df_entity_counter, on='head', how='left')\n",
    "    df_entity_counter.columns = ['tail', 'num_t']\n",
    "    df = pd.merge(df, df_entity_counter, on='tail', how='left')\n",
    "    df_rela_counter.columns = ['relationship', 'num_r']\n",
    "    df = pd.merge(df, df_rela_counter, on='relationship', how='left')\n",
    "    df = df[df['num_h'] >= 10]\n",
    "    df = df[df['num_t'] >= 10]\n",
    "    df = df[df['num_r'] >= 20]\n",
    "    df = df[['head', 'relationship', 'tail']]\n",
    "    entity_num = len(pd.concat([df['head'], df['tail']]).unique())\n",
    "    rela_num = len(df['relationship'].unique())\n",
    "    triplets_num = df.shape[0]\n",
    "    print(p, triplets_num, entity_num, rela_num)\n",
    "#     df.to_csv(p[:-4] + '_dropLess50.csv', sep='\\t', header=None, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
