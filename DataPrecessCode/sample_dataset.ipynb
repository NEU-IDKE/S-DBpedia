{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbd33316",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20892057",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = [\n",
    "    './data/DBpedia_combin/DBpedia_duplicates_filterOntology_dropMaxRelationship_filterGeo.csv',\n",
    "    './data/DBpedia_combin/DBpedia_duplicates_filterOntology_dropMaxRelationship_filterGeo_sampleSeed10.csv',\n",
    "    './data/DBpedia_combin/DBpedia_duplicates_filterOntology_dropMaxRelationship_filterGeo_dropLessHalfEntAndRela.csv',\n",
    "    './data/DBpedia_combin/DBpedia_duplicates_filterOntology_dropMaxRelationship_filterGeo_dropMost5PersentEntAndRela.csv'\n",
    "]\n",
    "geo_path = './data/DBpedia_combin/DBpedia-geo.csv'\n",
    "outdir = './final_dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a60bc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_scale(df_data):\n",
    "    entity_num = len(pd.concat([df_data['head'], df_data['tail']]).unique())\n",
    "    rela_num = len(df_data['relationship'].unique())\n",
    "    triplets_num = df_data.shape[0]\n",
    "    return triplets_num, entity_num, rela_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdef3b8",
   "metadata": {},
   "source": [
    "## 生成数据集S-DBpedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bc539d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_val: 227574 (227574, 241719, 230)\n",
      "df_test: 227574  (227574, 241526, 222)\n",
      "after filter:\n",
      "df_val: 195104 (195104, 206618, 208)\n",
      "df_test: 195106  (195106, 206578, 209)\n",
      "final:\n",
      "df_train: (1820591, 879610, 305)\n",
      "df_val: (195104, 206618, 208)\n",
      "df_test: (195106, 206578, 209)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_path[0], sep='\\t', names=['head', 'relationship', 'tail'])\n",
    "np.random.seed(99)\n",
    "df = df.sample(frac=1.0)\n",
    "df = df.reset_index(drop=True)\n",
    "val_index = round(0.8 * df.shape[0])\n",
    "test_index = round(0.9 * df.shape[0])\n",
    "df_train = df.iloc[:val_index]\n",
    "df_val = df.iloc[val_index: test_index]\n",
    "df_test = df.iloc[test_index:]\n",
    "ent = pd.concat([df_train['head'], df_train['tail']]).unique()\n",
    "relationship = df_train['relationship'].unique()\n",
    "df_head = pd.DataFrame({'head': ent, '1': True})\n",
    "df_tail = pd.DataFrame({'tail': ent, '2': True})\n",
    "df_rela = pd.DataFrame({'relationship': relationship, '3': True})\n",
    "df_val = pd.merge(df_val, df_head, on='head', how='left')\n",
    "df_val = pd.merge(df_val, df_tail, on='tail', how='left')\n",
    "df_val = pd.merge(df_val, df_rela, on='relationship', how='left')\n",
    "df_test = pd.merge(df_test, df_head, on='head', how='left')\n",
    "df_test = pd.merge(df_test, df_tail, on='tail', how='left')\n",
    "df_test = pd.merge(df_test, df_rela, on='relationship', how='left')\n",
    "print(f'df_val: {df_val.shape[0]} {count_scale(df_val)}\\ndf_test: {df_test.shape[0]}  {count_scale(df_test)}')\n",
    "df_val = df_val[df_val['1'] == True]\n",
    "df_val = df_val[df_val['2'] == True]\n",
    "df_val = df_val[df_val['3'] == True]\n",
    "df_test = df_test[df_test['1'] == True]\n",
    "df_test = df_test[df_test['2'] == True]\n",
    "df_test = df_test[df_test['3'] == True]\n",
    "df_val = df_val[['head', 'relationship', 'tail']]\n",
    "df_test = df_test[['head', 'relationship', 'tail']]\n",
    "print(f'after filter:\\ndf_val: {df_val.shape[0]} {count_scale(df_val)}\\ndf_test: {df_test.shape[0]}  {count_scale(df_test)}')\n",
    "print(f'final:\\ndf_train: {count_scale(df_train)}\\ndf_val: {count_scale(df_val)}\\ndf_test: {count_scale(df_test)}')\n",
    "df_train.to_csv(outdir + '/S-DBpedia/train.csv', sep='\\t', header=None, index=None)\n",
    "df_val.to_csv(outdir + '/S-DBpedia/valid.csv', sep='\\t', header=None, index=None)\n",
    "df_test.to_csv(outdir + '/S-DBpedia/test.csv', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c53cc9",
   "metadata": {},
   "source": [
    "## 生成数据集S-DBpedia-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec0b6ed2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_val: 113787 (113787, 134846, 214)\n",
      "df_test: 113787  (113787, 134826, 208)\n",
      "after filter:\n",
      "df_val: 69577 (69577, 83960, 179)\n",
      "df_test: 69603  (69603, 83937, 185)\n",
      "final:\n",
      "df_train: (910296, 650120, 278)\n",
      "df_val: (69577, 83960, 179)\n",
      "df_test: (69603, 83937, 185)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_path[1], sep='\\t', names=['head', 'relationship', 'tail'])\n",
    "np.random.seed(99)\n",
    "df = df.sample(frac=1.0)\n",
    "df = df.reset_index(drop=True)\n",
    "val_index = round(0.8 * df.shape[0])\n",
    "test_index = round(0.9 * df.shape[0])\n",
    "df_train = df.iloc[:val_index]\n",
    "df_val = df.iloc[val_index: test_index]\n",
    "df_test = df.iloc[test_index:]\n",
    "ent = pd.concat([df_train['head'], df_train['tail']]).unique()\n",
    "relationship = df_train['relationship'].unique()\n",
    "df_head = pd.DataFrame({'head': ent, '1': True})\n",
    "df_tail = pd.DataFrame({'tail': ent, '2': True})\n",
    "df_rela = pd.DataFrame({'relationship': relationship, '3': True})\n",
    "df_val = pd.merge(df_val, df_head, on='head', how='left')\n",
    "df_val = pd.merge(df_val, df_tail, on='tail', how='left')\n",
    "df_val = pd.merge(df_val, df_rela, on='relationship', how='left')\n",
    "df_test = pd.merge(df_test, df_head, on='head', how='left')\n",
    "df_test = pd.merge(df_test, df_tail, on='tail', how='left')\n",
    "df_test = pd.merge(df_test, df_rela, on='relationship', how='left')\n",
    "print(f'df_val: {df_val.shape[0]} {count_scale(df_val)}\\ndf_test: {df_test.shape[0]}  {count_scale(df_test)}')\n",
    "df_val = df_val[df_val['1'] == True]\n",
    "df_val = df_val[df_val['2'] == True]\n",
    "df_val = df_val[df_val['3'] == True]\n",
    "df_test = df_test[df_test['1'] == True]\n",
    "df_test = df_test[df_test['2'] == True]\n",
    "df_test = df_test[df_test['3'] == True]\n",
    "df_val = df_val[['head', 'relationship', 'tail']]\n",
    "df_test = df_test[['head', 'relationship', 'tail']]\n",
    "print(f'after filter:\\ndf_val: {df_val.shape[0]} {count_scale(df_val)}\\ndf_test: {df_test.shape[0]}  {count_scale(df_test)}')\n",
    "print(f'final:\\ndf_train: {count_scale(df_train)}\\ndf_val: {count_scale(df_val)}\\ndf_test: {count_scale(df_test)}')\n",
    "df_train.to_csv(outdir + '/S-DBpedia-large/train.csv', sep='\\t', header=None, index=None)\n",
    "df_val.to_csv(outdir + '/S-DBpedia-large/valid.csv', sep='\\t', header=None, index=None)\n",
    "df_test.to_csv(outdir + '/S-DBpedia-large/test.csv', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d734b04",
   "metadata": {},
   "source": [
    "## 生成数据集 halfER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "210ecd41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_val: 152621 (152621, 157847, 154)\n",
      "df_test: 152622  (152622, 157852, 152)\n",
      "after filter:\n",
      "df_val: 148177 (148177, 154463, 152)\n",
      "df_test: 148240  (148240, 154479, 152)\n",
      "final:\n",
      "df_train: (1220973, 461379, 157)\n",
      "df_val: (148177, 154463, 152)\n",
      "df_test: (148240, 154479, 152)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_path[2], sep='\\t', names=['head', 'relationship', 'tail'])\n",
    "np.random.seed(99)\n",
    "df = df.sample(frac=1.0)\n",
    "df = df.reset_index(drop=True)\n",
    "val_index = round(0.8 * df.shape[0])\n",
    "test_index = round(0.9 * df.shape[0])\n",
    "df_train = df.iloc[:val_index]\n",
    "df_val = df.iloc[val_index: test_index]\n",
    "df_test = df.iloc[test_index:]\n",
    "ent = pd.concat([df_train['head'], df_train['tail']]).unique()\n",
    "relationship = df_train['relationship'].unique()\n",
    "df_head = pd.DataFrame({'head': ent, '1': True})\n",
    "df_tail = pd.DataFrame({'tail': ent, '2': True})\n",
    "df_rela = pd.DataFrame({'relationship': relationship, '3': True})\n",
    "df_val = pd.merge(df_val, df_head, on='head', how='left')\n",
    "df_val = pd.merge(df_val, df_tail, on='tail', how='left')\n",
    "df_val = pd.merge(df_val, df_rela, on='relationship', how='left')\n",
    "df_test = pd.merge(df_test, df_head, on='head', how='left')\n",
    "df_test = pd.merge(df_test, df_tail, on='tail', how='left')\n",
    "df_test = pd.merge(df_test, df_rela, on='relationship', how='left')\n",
    "print(f'df_val: {df_val.shape[0]} {count_scale(df_val)}\\ndf_test: {df_test.shape[0]}  {count_scale(df_test)}')\n",
    "df_val = df_val[df_val['1'] == True]\n",
    "df_val = df_val[df_val['2'] == True]\n",
    "df_val = df_val[df_val['3'] == True]\n",
    "df_test = df_test[df_test['1'] == True]\n",
    "df_test = df_test[df_test['2'] == True]\n",
    "df_test = df_test[df_test['3'] == True]\n",
    "df_val = df_val[['head', 'relationship', 'tail']]\n",
    "df_test = df_test[['head', 'relationship', 'tail']]\n",
    "print(f'after filter:\\ndf_val: {df_val.shape[0]} {count_scale(df_val)}\\ndf_test: {df_test.shape[0]}  {count_scale(df_test)}')\n",
    "print(f'final:\\ndf_train: {count_scale(df_train)}\\ndf_val: {count_scale(df_val)}\\ndf_test: {count_scale(df_test)}')\n",
    "df_train.to_csv(outdir + '/DBpedia-halfER/train.csv', sep='\\t', header=None, index=None)\n",
    "df_val.to_csv(outdir + '/DBpedia-halfER/valid.csv', sep='\\t', header=None, index=None)\n",
    "df_test.to_csv(outdir + '/DBpedia-halfER/test.csv', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d43ff6d",
   "metadata": {},
   "source": [
    "## 生成数据集 DPM5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dc81c55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_val: 3323 (3323, 6375, 154)\n",
      "df_test: 3324  (3324, 6375, 158)\n",
      "after filter:\n",
      "df_val: 621 (621, 1211, 82)\n",
      "df_test: 566  (566, 1091, 86)\n",
      "final:\n",
      "df_train: (26589, 40827, 250)\n",
      "df_val: (621, 1211, 82)\n",
      "df_test: (566, 1091, 86)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data_path[3], sep='\\t', names=['head', 'relationship', 'tail'])\n",
    "np.random.seed(99)\n",
    "df = df.sample(frac=1.0)\n",
    "df = df.reset_index(drop=True)\n",
    "val_index = round(0.8 * df.shape[0])\n",
    "test_index = round(0.9 * df.shape[0])\n",
    "df_train = df.iloc[:val_index]\n",
    "df_val = df.iloc[val_index: test_index]\n",
    "df_test = df.iloc[test_index:]\n",
    "ent = pd.concat([df_train['head'], df_train['tail']]).unique()\n",
    "relationship = df_train['relationship'].unique()\n",
    "df_head = pd.DataFrame({'head': ent, '1': True})\n",
    "df_tail = pd.DataFrame({'tail': ent, '2': True})\n",
    "df_rela = pd.DataFrame({'relationship': relationship, '3': True})\n",
    "df_val = pd.merge(df_val, df_head, on='head', how='left')\n",
    "df_val = pd.merge(df_val, df_tail, on='tail', how='left')\n",
    "df_val = pd.merge(df_val, df_rela, on='relationship', how='left')\n",
    "df_test = pd.merge(df_test, df_head, on='head', how='left')\n",
    "df_test = pd.merge(df_test, df_tail, on='tail', how='left')\n",
    "df_test = pd.merge(df_test, df_rela, on='relationship', how='left')\n",
    "print(f'df_val: {df_val.shape[0]} {count_scale(df_val)}\\ndf_test: {df_test.shape[0]}  {count_scale(df_test)}')\n",
    "df_val = df_val[df_val['1'] == True]\n",
    "df_val = df_val[df_val['2'] == True]\n",
    "df_val = df_val[df_val['3'] == True]\n",
    "df_test = df_test[df_test['1'] == True]\n",
    "df_test = df_test[df_test['2'] == True]\n",
    "df_test = df_test[df_test['3'] == True]\n",
    "df_val = df_val[['head', 'relationship', 'tail']]\n",
    "df_test = df_test[['head', 'relationship', 'tail']]\n",
    "print(f'after filter:\\ndf_val: {df_val.shape[0]} {count_scale(df_val)}\\ndf_test: {df_test.shape[0]}  {count_scale(df_test)}')\n",
    "print(f'final:\\ndf_train: {count_scale(df_train)}\\ndf_val: {count_scale(df_val)}\\ndf_test: {count_scale(df_test)}')\n",
    "df_train.to_csv(outdir + '/DBpedia-DPM5/train.csv', sep='\\t', header=None, index=None)\n",
    "df_val.to_csv(outdir + '/DBpedia-DPM5/valid.csv', sep='\\t', header=None, index=None)\n",
    "df_test.to_csv(outdir + '/DBpedia-DPM5/test.csv', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0ff8fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed:10\n",
      "df_val: 3323 (3323, 6324, 158)\n",
      "df_test: 3324  (3324, 6322, 154)\n",
      "after filter:\n",
      "df_val: 625 (625, 1213, 83)\n",
      "df_test: 589  (589, 1138, 81)\n",
      "final:\n",
      "df_train: (26589, 40903, 256)\n",
      "df_val: (625, 1213, 83)\n",
      "df_test: (589, 1138, 81)\n",
      "seed:45\n",
      "df_val: 3323 (3323, 6365, 156)\n",
      "df_test: 3324  (3324, 6366, 168)\n",
      "after filter:\n",
      "df_val: 623 (623, 1202, 79)\n",
      "df_test: 602  (602, 1162, 90)\n",
      "final:\n",
      "df_train: (26589, 40853, 248)\n",
      "df_val: (623, 1202, 79)\n",
      "df_test: (602, 1162, 90)\n",
      "seed:68\n",
      "df_val: 3323 (3323, 6344, 160)\n",
      "df_test: 3324  (3324, 6353, 160)\n",
      "after filter:\n",
      "df_val: 588 (588, 1141, 82)\n",
      "df_test: 617  (617, 1184, 89)\n",
      "final:\n",
      "df_train: (26589, 40888, 251)\n",
      "df_val: (588, 1141, 82)\n",
      "df_test: (617, 1184, 89)\n",
      "seed:77\n",
      "df_val: 3323 (3323, 6344, 157)\n",
      "df_test: 3324  (3324, 6359, 156)\n",
      "after filter:\n",
      "df_val: 558 (558, 1083, 90)\n",
      "df_test: 596  (596, 1152, 86)\n",
      "final:\n",
      "df_train: (26589, 40807, 253)\n",
      "df_val: (558, 1083, 90)\n",
      "df_test: (596, 1152, 86)\n"
     ]
    }
   ],
   "source": [
    "seeds = [10, 45, 68, 77]\n",
    "for seed in seeds: \n",
    "    print(f'seed:{seed}')\n",
    "    df = pd.read_csv(data_path[3], sep='\\t', names=['head', 'relationship', 'tail'])\n",
    "    np.random.seed(seed)\n",
    "    df = df.sample(frac=1.0)\n",
    "    df = df.reset_index(drop=True)\n",
    "    val_index = round(0.8 * df.shape[0])\n",
    "    test_index = round(0.9 * df.shape[0])\n",
    "    df_train = df.iloc[:val_index]\n",
    "    df_val = df.iloc[val_index: test_index]\n",
    "    df_test = df.iloc[test_index:]\n",
    "    ent = pd.concat([df_train['head'], df_train['tail']]).unique()\n",
    "    relationship = df_train['relationship'].unique()\n",
    "    df_head = pd.DataFrame({'head': ent, '1': True})\n",
    "    df_tail = pd.DataFrame({'tail': ent, '2': True})\n",
    "    df_rela = pd.DataFrame({'relationship': relationship, '3': True})\n",
    "    df_val = pd.merge(df_val, df_head, on='head', how='left')\n",
    "    df_val = pd.merge(df_val, df_tail, on='tail', how='left')\n",
    "    df_val = pd.merge(df_val, df_rela, on='relationship', how='left')\n",
    "    df_test = pd.merge(df_test, df_head, on='head', how='left')\n",
    "    df_test = pd.merge(df_test, df_tail, on='tail', how='left')\n",
    "    df_test = pd.merge(df_test, df_rela, on='relationship', how='left')\n",
    "    print(f'df_val: {df_val.shape[0]} {count_scale(df_val)}\\ndf_test: {df_test.shape[0]}  {count_scale(df_test)}')\n",
    "    df_val = df_val[df_val['1'] == True]\n",
    "    df_val = df_val[df_val['2'] == True]\n",
    "    df_val = df_val[df_val['3'] == True]\n",
    "    df_test = df_test[df_test['1'] == True]\n",
    "    df_test = df_test[df_test['2'] == True]\n",
    "    df_test = df_test[df_test['3'] == True]\n",
    "    df_val = df_val[['head', 'relationship', 'tail']]\n",
    "    df_test = df_test[['head', 'relationship', 'tail']]\n",
    "    print(f'after filter:\\ndf_val: {df_val.shape[0]} {count_scale(df_val)}\\ndf_test: {df_test.shape[0]}  {count_scale(df_test)}')\n",
    "    print(f'final:\\ndf_train: {count_scale(df_train)}\\ndf_val: {count_scale(df_val)}\\ndf_test: {count_scale(df_test)}')\n",
    "    df_train.to_csv(outdir + f'/DBpedia-DPM5-{seed}/train.csv', sep='\\t', header=None, index=None)\n",
    "    df_val.to_csv(outdir + f'/DBpedia-DPM5-{seed}/valid.csv', sep='\\t', header=None, index=None)\n",
    "    df_test.to_csv(outdir + f'/DBpedia-DPM5-{seed}/test.csv', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614fc34f",
   "metadata": {},
   "source": [
    "## 生成数据集 S-DBpedia-GTnE系列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6407c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = [\n",
    "    './data/DBpedia_combin/DBpedia_duplicates_filterOntology_dropMaxRelationship_filterGeo_get5Ent.csv',\n",
    "    './data/DBpedia_combin/DBpedia_duplicates_filterOntology_dropMaxRelationship_filterGeo_get10Ent.csv',\n",
    "    './data/DBpedia_combin/DBpedia_duplicates_filterOntology_dropMaxRelationship_filterGeo_get20Ent.csv',\n",
    "    './data/DBpedia_combin/DBpedia_duplicates_filterOntology_dropMaxRelationship_filterGeo_get50Ent.csv'\n",
    "]\n",
    "outdir = './final_dataset/'\n",
    "dataset_names = [f'S-DBpedia-GT{i}E' for i in [5, 10, 20, 50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "909585bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_val: 16103 (16103, 18329, 126)\n",
      "df_test: 16103  (16103, 18353, 128)\n",
      "after filter:\n",
      "df_val: 15393 (15393, 17570, 123)\n",
      "df_test: 15339  (15339, 17539, 125)\n",
      "final:\n",
      "df_train: (128823, 44187, 169)\n",
      "df_val: (15393, 17570, 123)\n",
      "df_test: (15339, 17539, 125)\n",
      "df_val: 33448 (33448, 37527, 159)\n",
      "df_test: 33448  (33448, 37244, 169)\n",
      "after filter:\n",
      "df_val: 32375 (32375, 36406, 158)\n",
      "df_test: 32381  (32381, 36171, 159)\n",
      "final:\n",
      "df_train: (267585, 90523, 229)\n",
      "df_val: (32375, 36406, 158)\n",
      "df_test: (32381, 36171, 159)\n",
      "df_val: 67767 (67767, 72138, 186)\n",
      "df_test: 67768  (67768, 72237, 189)\n",
      "after filter:\n",
      "df_val: 66260 (66260, 70772, 177)\n",
      "df_test: 66355  (66355, 70925, 184)\n",
      "final:\n",
      "df_train: (542141, 183706, 253)\n",
      "df_val: (66260, 70772, 177)\n",
      "df_test: (66355, 70925, 184)\n",
      "df_val: 152705 (152705, 157967, 201)\n",
      "df_test: 152705  (152705, 157980, 202)\n",
      "after filter:\n",
      "df_val: 148239 (148239, 154584, 197)\n",
      "df_test: 148475  (148475, 154750, 199)\n",
      "final:\n",
      "df_train: (1221639, 461516, 281)\n",
      "df_val: (148239, 154584, 197)\n",
      "df_test: (148475, 154750, 199)\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(data_path):\n",
    "    df = pd.read_csv(p, sep='\\t', names=['head', 'relationship', 'tail'])\n",
    "    np.random.seed(99)\n",
    "    df = df.sample(frac=1.0)\n",
    "    df = df.reset_index(drop=True)\n",
    "    val_index = round(0.8 * df.shape[0])\n",
    "    test_index = round(0.9 * df.shape[0])\n",
    "    df_train = df.iloc[:val_index]\n",
    "    df_val = df.iloc[val_index: test_index]\n",
    "    df_test = df.iloc[test_index:]\n",
    "    ent = pd.concat([df_train['head'], df_train['tail']]).unique()\n",
    "    relationship = df_train['relationship'].unique()\n",
    "    df_head = pd.DataFrame({'head': ent, '1': True})\n",
    "    df_tail = pd.DataFrame({'tail': ent, '2': True})\n",
    "    df_rela = pd.DataFrame({'relationship': relationship, '3': True})\n",
    "    df_val = pd.merge(df_val, df_head, on='head', how='left')\n",
    "    df_val = pd.merge(df_val, df_tail, on='tail', how='left')\n",
    "    df_val = pd.merge(df_val, df_rela, on='relationship', how='left')\n",
    "    df_test = pd.merge(df_test, df_head, on='head', how='left')\n",
    "    df_test = pd.merge(df_test, df_tail, on='tail', how='left')\n",
    "    df_test = pd.merge(df_test, df_rela, on='relationship', how='left')\n",
    "    print(f'df_val: {df_val.shape[0]} {count_scale(df_val)}\\ndf_test: {df_test.shape[0]}  {count_scale(df_test)}')\n",
    "    df_val = df_val[df_val['1'] == True]\n",
    "    df_val = df_val[df_val['2'] == True]\n",
    "    df_val = df_val[df_val['3'] == True]\n",
    "    df_test = df_test[df_test['1'] == True]\n",
    "    df_test = df_test[df_test['2'] == True]\n",
    "    df_test = df_test[df_test['3'] == True]\n",
    "    df_val = df_val[['head', 'relationship', 'tail']]\n",
    "    df_test = df_test[['head', 'relationship', 'tail']]\n",
    "    print(f'after filter:\\ndf_val: {df_val.shape[0]} {count_scale(df_val)}\\ndf_test: {df_test.shape[0]}  {count_scale(df_test)}')\n",
    "    print(f'final:\\ndf_train: {count_scale(df_train)}\\ndf_val: {count_scale(df_val)}\\ndf_test: {count_scale(df_test)}')\n",
    "    df_train.to_csv(outdir + dataset_names[i] + '/train.csv', sep='\\t', header=None, index=None)\n",
    "    df_val.to_csv(outdir + dataset_names[i] + '/valid.csv', sep='\\t', header=None, index=None)\n",
    "    df_test.to_csv(outdir + dataset_names[i] + '/test.csv', sep='\\t', header=None, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786bc927",
   "metadata": {},
   "source": [
    "## 生成数据集RDM系列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe17789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = [\n",
    "    './data/DBpedia_combin/DBpedia_duplicates_filterOntology_dropMaxRelationship_filterGeo_sample12.csv',\n",
    "    './data/DBpedia_combin/DBpedia_duplicates_filterOntology_dropMaxRelationship_filterGeo_sample25.csv'\n",
    "]\n",
    "outdir = './final_dataset/'\n",
    "dataset_names = ['S-DBpedia_small', 'S-DBpedia_medium']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89f9fb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_val: 28446 (28446, 39234, 148)\n",
      "df_test: 28447  (28447, 39225, 155)\n",
      "after filter:\n",
      "df_val: 6026 (6026, 8986, 96)\n",
      "df_test: 6107  (6107, 9066, 102)\n",
      "final:\n",
      "df_train: (227574, 241869, 221)\n",
      "df_val: (6026, 8986, 96)\n",
      "df_test: (6107, 9066, 102)\n",
      "df_val: 56894 (56894, 73271, 176)\n",
      "df_test: 56893  (56893, 73286, 174)\n",
      "after filter:\n",
      "df_val: 21108 (21108, 28534, 128)\n",
      "df_test: 21439  (21439, 28975, 132)\n",
      "final:\n",
      "df_train: (455148, 413157, 247)\n",
      "df_val: (21108, 28534, 128)\n",
      "df_test: (21439, 28975, 132)\n"
     ]
    }
   ],
   "source": [
    "for i, p in enumerate(data_path):\n",
    "    df = pd.read_csv(p, sep='\\t', names=['head', 'relationship', 'tail'])\n",
    "    np.random.seed(99)\n",
    "    df = df.sample(frac=1.0)\n",
    "    df = df.reset_index(drop=True)\n",
    "    val_index = round(0.8 * df.shape[0])\n",
    "    test_index = round(0.9 * df.shape[0])\n",
    "    df_train = df.iloc[:val_index]\n",
    "    df_val = df.iloc[val_index: test_index]\n",
    "    df_test = df.iloc[test_index:]\n",
    "    ent = pd.concat([df_train['head'], df_train['tail']]).unique()\n",
    "    relationship = df_train['relationship'].unique()\n",
    "    df_head = pd.DataFrame({'head': ent, '1': True})\n",
    "    df_tail = pd.DataFrame({'tail': ent, '2': True})\n",
    "    df_rela = pd.DataFrame({'relationship': relationship, '3': True})\n",
    "    df_val = pd.merge(df_val, df_head, on='head', how='left')\n",
    "    df_val = pd.merge(df_val, df_tail, on='tail', how='left')\n",
    "    df_val = pd.merge(df_val, df_rela, on='relationship', how='left')\n",
    "    df_test = pd.merge(df_test, df_head, on='head', how='left')\n",
    "    df_test = pd.merge(df_test, df_tail, on='tail', how='left')\n",
    "    df_test = pd.merge(df_test, df_rela, on='relationship', how='left')\n",
    "    print(f'df_val: {df_val.shape[0]} {count_scale(df_val)}\\ndf_test: {df_test.shape[0]}  {count_scale(df_test)}')\n",
    "    df_val = df_val[df_val['1'] == True]\n",
    "    df_val = df_val[df_val['2'] == True]\n",
    "    df_val = df_val[df_val['3'] == True]\n",
    "    df_test = df_test[df_test['1'] == True]\n",
    "    df_test = df_test[df_test['2'] == True]\n",
    "    df_test = df_test[df_test['3'] == True]\n",
    "    df_val = df_val[['head', 'relationship', 'tail']]\n",
    "    df_test = df_test[['head', 'relationship', 'tail']]\n",
    "    print(f'after filter:\\ndf_val: {df_val.shape[0]} {count_scale(df_val)}\\ndf_test: {df_test.shape[0]}  {count_scale(df_test)}')\n",
    "    print(f'final:\\ndf_train: {count_scale(df_train)}\\ndf_val: {count_scale(df_val)}\\ndf_test: {count_scale(df_test)}')\n",
    "    df_train.to_csv(outdir + dataset_names[i] + '/train.csv', sep='\\t', header=None, index=None)\n",
    "    df_val.to_csv(outdir + dataset_names[i] + '/valid.csv', sep='\\t', header=None, index=None)\n",
    "    df_test.to_csv(outdir + dataset_names[i] + '/test.csv', sep='\\t', header=None, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
